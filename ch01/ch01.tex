\chapter{Electrostatics: charges and fields}

\section{Electric charge}\index{charge}

Electricity appeared to its early investigators as an extraordinary phenomenon.
To draw from bodies the \emph{subtle fire}, as it was
sometimes called, to bring an object into a highly electrified state, to
produce a steady flow of current, called for skillful contrivance. Except for
the spectacle of lightning, the ordinary manifestations of nature, from the
freezing of water to the growth of a tree, seemed to have no relation to the
curious behavior of electrified objects. We know now that electrical forces
largely determine the physical and chemical properties of matter over the whole
range from atom to living cell. For this understanding we have to thank the
scientists of the nineteenth century, Ampere, Faraday, Maxwell, and many
others, who discovered the nature of electromagnetism,, as well as the
physicists and chemist of the twentieth century who unraveled the atomic
structure of matter. 

Classical electromagnetism deals with electric charges and
currents and their interactions as if all the quantities involved could be
measured independently, with unlimited precision. Here \emph{classical} means
simply ``non-quantum.'' The quantum law with its constant $h$ is ignored in the
classical theory of electromagnetism, just as it is in ordinary mechanics. Indeed,
the classical theory was brought very nearly to its present state of completion
before Planck's discovery. It has survived remarkably well. Neither the
revolution of quantum physics nor the development of special relativity dimmed
the luster of the electromagnetic field equations Maxwell wrote down a hundred
years ago. 

Of course, the theory was solidly based on experiment, and
because of that was fairly secure within its original range of application --to
coils, capacitors, oscillating currents, eventually radio waves and light
waves. But even so great a success does not guarantee validity in another
domain, for instance, the inside of a molecule.

Two facts help explain the continuing importance in modern
physics of the classical description of electromagnetism. First, special
relativity required no revision of classical electromagnetism. Historically
speaking, special relativity \emph{grew out of} classical electromagnetic
theory and experiments inspired by it. Maxwell's field equations, developed
long before the work of Lorentz and Einstein, proved to be entirely compatible
with relativity. Second, quantum modifications of the electromagnetic force
have turned out to be unimportant down to distances less than $10^{-10}\ \textup{cm}$, a
hundred times smaller than the atom. We can describe the repulsion and
attraction of particles in the atom using the same laws that apply to the
leaves of an electroscope, although we need quantum mechanics to predict how
the particles will behave under those forces. For still smaller distances,
there is a rather successful fusion of electromagnetic theory and quantum
theory, called \emph{quantum electrodynamics}, which seems to agree with
experiment down to the smallest distances yet explored. 

We assume the reader has some acquaintance with elementary
facts of electricity. We are not going to review all the experiments by which
the existence of electric was demonstrated or all the evidence for the
electrical constitution of matter. On the other hand, we do want to look
carefully at the experimental foundations of the basic laws on which all else
depends. In this chapter we shall study the physics of stationary electric
charges --- \emph{electrostatics}.

Certainly one fundamental property of electric charge is its
existence I the two varieties that were long ago named positive and negative.
The observed fact is that all charged particles can be divided into two classes
such that all members of one class repel each other, while attracting members
of the other class. If two small electrically charged bodies $A$ and
$B$, some distance apart, repel one another, and if $A$ attracts some
third electrified body $C$, then we always find that $B$ attracts
$C$. Why this universal law prevails we cannot say for sure. But today
physicists tend to regard positive and negative charge as, fundamentally,
opposite manifestations of one quality, much as ``right'' and ``left'' are
opposite manifestations of ``handedness.'' Indeed, the question of symmetry
involved in right and left seems to be intimately related to this duality of
electric charge, and to another fundamental symmetry, the two directions of
time. Elementary particle physics is throwing some light on these questions.

What we call negative charge could just as well have been
called positive, and vice versa.\footnote{The charge of the ordinary electron has nothing
\emph{intrinsically negative} about it. A negative integer, once multiplication has been
defined, differs essentially from a positive integer in that its square is an integer of
opposite sign. But the product of two charges is not a charge; there is no comparison.}
The choice was a historical accident. Our
universe appears to be very evenly balanced mixture of positive and negative
electric charge which, since like charges repel one another is not surprising. 

Two other observed properties of electric charge are
essential in the electrical structure of matter: charge is conserved, and
charge is quantized. These properties involve \emph{quantity} of charge, and
thus imply a measurement of charge. Presently we shall state precisely how
charge can be measured in terms of the force between charges a certain distance
apart, and so on. But let us take this for granted, for the time being, so that
we may talk freely about these fundamental facts. 

\section{Conservation of charge}\index{charge!conservation of}\index{conservation!of charge}

The total charge in an isolated system never changes. By
\emph{isolated} we mean that no matter is allowed to cross the boundary of the
system. We could let light pass into or out of the system without affecting the
principle, since photons carry no charge. For instance, a thin-walled box in
vacuum, exposed to gamma rays, might become the scene of a ``pair-creation''
event in which a high-energy photon ends its existence with the creation of a
negative electron and a positive electron (Fig.~1.1). Two electrically charged
particles have been newly created but the net change in total charge, in and on
the box, is zero. An event that \emph{would} violate the law we have just
stated would be the creation of a positively charged particle \emph{without}
the simultaneous creation of a negatively charged particle. Such an occurrence
has never been observed. 

Of course, if the electric charges of electron and positron
were not precisely equal in magnitude, pair creation would still violate the
strict law of charge conservation. As well as can be determined from
experiment, their charges \emph{are} equal. An interesting experimental test is
provided by the structure called \emph{positronium}, a structure composed of an
electron and a positron, and nothing else. This curious ``atom'' can live long
enough-a tenth of a microsecond or so-to be studied in detail. It behaves as if
it were quite neutral, electrically. Actually, most physicists would be
astonished, not to say incredulous, if \emph{any} difference were found in the
magnitudes of these charges, for we know that electron and positron are related
to one another as \emph{particle} to \emph{antiparticle}. Their exact equality
of charge, like their equality of mass, is a manifestation of an apparently
universal symmetry in nature, the particle-antiparticle duality. One might
wonder whether charge conservation, then, is merely a corollary of some broader
conservation law governing the creation and annihilation of particles; or is
charge conservation a primary requirement, with which other laws have to fall
in line? Or do these questions make sense? We do not know for sure. 

One thing will become clear in the course of our study of
electromagnetism: nonconservation of charge would be quite incompatible with
the structure of our present electromagnetic theory. We may therefore state
either as a postulate of the theory or as an empirical law supported without
exception by all observations so far, the \emph{charge conservation law:}

The total electric charge in an isolated system, that is, the
algebraic sum of the positive and negative charge present at any time, never
changes. 

Sooner or later we must ask whether this law meets the test
of relativistic invariance. We shall postpone until Chap. 5 a thorough
discussion of this important question. But the answer is that it does, and not
merely in the sense that the statement above holds in any given inertial frame,
but in the stronger sense that observer in different frames, measuring the
charge, get the same number. In other words the total electric charge of an
isolated system is relativistically invariant number. 

\section{Quantization of charge}\index{charge!quantization of}\index{quantization of charge}

Millikan's oil-drop experiment,\index{Millikan oil drop experiment} and innumerable other
experiments, have shown that in nature electric charge comes in units of one
magnitude only. That magnitude we denote by $e$, the electronic charge. We have
already noted that the positron has precisely this amount of charge. What seems
more remarkable is the exact equality in the charges carried by all other
charged particles-the equality, for instance, in the magnitude of the positive
charge on the proton and the negative charge on the electron. 

That particular equality, the proton-electron charge
balance, is open to a very sensitive test. One can test the normal hydrogen
atom or molecule for overall electrical neutrality. Thus, one could try to
deflect a beam of atoms or molecules by an electrical field. In a sensitive
experiment devised for this purpose,\footnote{J.C.~Zorn, G.E.~Chamberlin,
and V.W.~Hughes, Phys. Rev. 129, 2566 (1963)} a sharply defined beam of cesium atoms was
sent, in a high vacuum, through a strong electric field. From the absence of
any observable deflection it could be concluded that the net charge on a cesium
atom must be less than $10^{-16}e$. An even more sensitive test has recently
been made by a different method.\footnote{J.G.~King, Phys. Rev. Letters 5, 562 (1960).
References to previous tests of charge equality will be found in this article and
in the chapter by V.W.~Hughes in Gravitation and Relativity, edited by H.Y.~Chiu and
W.F.~Hoffman (W.A.~Benjamin, Inc., New York, 1964), chap. 13.} A large amount of hydrogen gas was compressed
into a tank which was itself highly insulated, electrically, from its
surroundings. The gas was then allowed to escape from the tank by means which
prevented the escape of any ordinary ions. \emph{If} the charge on the proton
differed from that on the electron by, say, one part in a billion, then each
hydrogen molecule, composed of two protons and two electrons, would carry a
charge of $2\times 10^{-9}e$, and the departure of the whole mass of hydrogen would
measurably alter the electrical charge and potential of the tank. In fact, the
experiment could have revealed a residual charge as small as $10^{-20}e$ per
atom, and none was observed! We conclude that the electron and proton have
equal charge, to an accuracy of 1 part in $10^{20}$. 

On present ideas, the electron and the proton are about as
unlike as two elementary particles can be. No one yet understands why their
charges should have to be equal to such a fantastically precise degree.
Evidently the quantization of charge is a deep and universal law of nature.
\emph{All} charged elementary particles, as far as we can determine, carry
charges of precisely the same magnitude. We can only hope that some future
discovery or theoretical insight may reveal to us why a particle with a charge
$0.500e$, or $0.999e$, cannot exist.\footnote{In some recent theoretical speculations
about elementary particles the possible existence of charge $\frac{1}{3}e$ and $\frac{2}{3}e$
was suggested. In a subsequent search for such particles, under conditions believed
favorable for their production and detection, none turned up. [L.B.~Leipuner, W.T.~Chu,
R.C.~Larsen, R.K.~Adair, Particles with a charge of $\frac{1}{3}e$, Phys. Rev. Letters 12, 423 (1964)].
As this is written, however, the speculation continues.}

The fact of charge quantization lies outside the scope of
classical electromagnetism, of course. We shall usually ignore it, and act as
if our point charges $q$ could have any strength whatever. This will not get us
into trouble. Still, it is worth remembering that classical theory cannot be
expected to explain the structure of the elementary particles. (It is not
certain that present quantum theory can either!) What holds the electron
together is as mysterious as what fixes the precise value of its charge.
Something more than electrical forces must be involved, for the electrostatic
forces between different parts of the electron would be repulsive. 

In our study of electricity and magnetism we shall treat the
charged particles simply as carriers of charge, with dimensions so small
that their extension and structure is for most purposes quite
insignificant. In the case of the proton for example, we know from
high-energy scattering experiments that the electric charge does not
extend appreciably beyond a radius of $10^{-13}$ cm. we recall that
Rutherford's analysis of the scattering of alpha particles showed
that even heavy nuclei have their electric charge distributed over a
region smaller than $10^{-11}$ cm. For the physicist of the
nineteenth century a ``point charge'' remained an abstract notion, of
which a charge pith ball was a pretty poor realization. Today we are
on familiar terms with the atomic particles. The graininess of
electricity is so conspicuous on our modern description of nature
that we find a point charge less of an artificial idealization than a
smoothly varying distributions, we may think of them as averages over
very large numbers of elementary charges, in the same way that we can
define the macroscopic density of a liquid, its lumpiness on a
molecular scale not withstanding. On objects much bigger than
Millikan's oil drops the quantization of charge is not very
noticeable!

\section{Coulomb's Law}

 As you probably already know, the interaction
between electric charges at rest is described by Coulomb's law: Two
stationary electric charges repel or attract one another with a force
proportional to the product of the magnitude of the charges and
inversely proportional to the square of the distance between them. We
can state this compactly in vector form: 

\begin{equation}
  \vc{F}_2=k\frac{q_1q_2\hat{\vc{r}}_{21}}{r_{21}^2}
\end{equation}
\noindent Here
$q_1$ and $q_2$ are numbers (scalars) giving the magnitude and sign
of the respective charges, $r_{21}$ is the unit vector in the direction
\footnote{The convention we adopt here may not seem the natural
choice but it is more consistent with the usage in some other parts
of physics and we shall try to follow it throughout this book.} from
charge 1 to charge 2, and $\vc{F}_2$ is the force acting on charge 2. Thus
Eq. 1 expresses, among other things, the fact that like charges repel
and unlike attract, and that the force is Newtonian; that is
$\vc{F}_2=-\vc{F}_1$. The unit vector $r_{21}$ shows that the force is parallel
to the line joining the charges. It could not be otherwise unless
space itself has some built-in directional property, for with two
point charges alone in empty and isotropic space, no other direction
could be singled out.

If the "point charge'' itself had some internal structure, with an
axis defining a direction, then it would have to be described by more
than the mere scalar quantity q. We suppose, in writing Eq. 1, that
both charges are we localized, occupying regions small compared to
$r_{21}$; if not, $r_{21}$ could not be defines so as to make Eq. 1
generally valid. The restriction to stationary charges is make for
the present, to exclude the question of magnetic forces arising from
moving charges, which we shall study in a later chapter. The constant
$k$ has been included in Eq. 1 to take care of the units. Usually we
shall choose to measure $r_{21}$ in centimeters;  $\vc{F}$ in dynes; and
charge in CGS \emph{electrostatic units}, or esu. In that case, $k$
is exactly one. Two charges each of one esu repel each other with a
force of one dyne when they are one centimeter apart; we may regard
Eq. 1, with $k$=1, as providing the definition of the unit of charge
in the CGS electrostatic system of units. Sometimes we shall use the
\emph{coulomb} as the unit of charge. This unit is usually
encountered in the company of meter-kilogram-second units. Its
magnitude is such that with charge expressed in coulombs, and
distance in meters, Eq. 1 gives the force in newtons, providing $k$
is given the value $8.9875\times 10^{9}$. The reason for introducing
the coulomb is its simple relation to the common electrical units
(ampere, volt, ohm, and watt), which we use in engineering, in the
laboratory, and in our everyday life. A charge of one coulomb amounts
to $2.988\times 10^{9}$ esu.\footnote {The number 2.998 which
appears above and will appear later in other electrical unit
conversions may remind you of the speed of light. In fact that is
where it comes from, by a route we need not now explore. Often you
will find in books and tables simply the factor 3 instead. Strictly,
every factor 3 in an electrical unit conversion ought to be
$2.99792\ldots$, or whatever is the established significant-figure part of
the speed of light in metric units.}

The only way we have of detection and measuring electric charges is
by observing the interaction of charges bodies. One might wonder,
then, how much of the apparent content of Coulomb's law is really
only definition. As is stands, the significant physical content is
the statement of inverse-square dependence, and the implication that
electric charge is \emph{additive} in its effect. To bring out the
latter point, we have to consider \emph{more} than two charges. After
all, if we had only two charges in he world to experiment with, $q_1$
and $q_2$, we could never measure them separately. We could verify
only that f is proportional to $1/r_{{21}}^2$. Suppose we have
\emph{three} bodies carrying charges $q_1$, $q_2$, and $q_3$. We can
measure the force on $q_1$ when $q_2$ is 10 cm away from $q_1$ and
$q_3$ is very far away, as in Fig.~1.2a. Then we can take $q_2$

Away, bring $q_3$ into $q_2$'s former position and again measure the
force on $q_1$. Finally, we bring $q_2$ and $q_3$ very close together
and locate the combination 10 cm from $q_1$. We find by measurement
that the force on $q_1$ is equal to the sum of the forces previously
measured. This is a significant result that could \emph{not} have
been predicted by logical arguments from symmetry like the one we
used above to show that the force between two points charges
\emph{had} to be along the line joining them. \emph{The force with
which two charges interact is not changes by the presence of a third
charge.} No matter how many charges we have in our system, Coulomb's
law (Eq. 1) can be used to calculate the interaction of every pair.
This is the basis of a principle of \emph{superposition}, which we
shall invoke again and again in our study of electromagnetism.
Superposition means combining two sets of sources into one system by
adding the second system "on top of'' the first without altering the
configuration of either one. Our principle assures us that the force
on a charge places at any point in the combined system will be the
vector sum of the forces that each set of sources, acting alone,
causes to act on a charge at that point. This principle must not be
taken lightly for granted. There may well be a domain of phenomena,
involving very small distances or very intense forces, where
superposition \emph{no longer holds}.  Indeed, we know of quantum
phenomena in the electromagnetic field which do represent a failure
of superposition, seen from the viewpoint of the classical theory.
Thus the physics of electrical interactions comes into full view only
when we have \emph{more} than two charges. We can go beyond the
explicit statement of Eq. 1 and assert that with the three charges in
Fig 1.2 occupying any positions whatever, the force on any one of
them, such as $q_3$, is correctly given by this equation: 

\begin{equation}
\vc{F}_3= \frac{q_3q_1\hat{\vc{r}}_{31}}{r_{31}^2}+\frac{q_3q_2\hat{\vc{r}}_{32}}{r_{32}^2}
\end{equation}

\noindent Equation 2 applies for
instance to the situation shown in Fig.~1.3. As for the
inverse-square law, its experimental verification, over a certain
range of distances, leaves little to be desired. In 1785 Coulomb
measured with a torsion balance the force between small charged
spheres. Many years before Coulomb, Priestly had suggested, by
analogy with the gravitational field, that the absence of electrical
influence inside a hollow charged sphere was proof of an
inverse-square force. Henry Cavendish, the British experimental
genius whose work was largely unknown to his contemporaries, carried
out in 1722 a test of the inverse-square law accurate to about 2
percent. Cavendish charges a spherical shell, which could then be
separated into two halves to expose an inner globe. The absence of
charge on the inner globe was proof of the inverse-square law.
\footnote {As we shall discuss in Chap. 3, the field is zero inside
any conducting shell, spherical or not. Cavendish, reasoning like
Priestley by analogy with gravitation, seems not to have been aware
of this more general consequence of the inverse-law square
law.} Modern repetitions of Cavendish's test \footnote{S.J.~Plimpton
and W.E.~Lawton, Phys.~Rev.~50, 1066 (1936).} have, in effect, checked
the inverse-square law, over distances of the order of inches or
feet, to an accuracy of a few parts in $10^{9}$.      Sometimes this
experimental result is described as a test of the ``exponent'' in the
inverse-square law. However, the real question is not whether -2 or
some other number like -1.99998 is the correct exponent, but rather
at what range of distances, if any, the inverse-square law breaks
down. There are two domains in either of which, for all we can prove
today by direct experiment, a breakdown might occur. The first is the
domain of very small distances, distances less than $10^{-14}$ cm
where, as we have already said, we have no assurance that
electromagnetic theory will work at all. But also at very
\emph{large} distances, from the geographical, say, to the
astronomical, we have no experimental test of Coulomb's law as such.
Now we have no particular reason to \emph{expect} a breakdown at
large distances very much greater than those used in the latter-day
Cavendish experiments. The reason is that cutoff, at large distances,
of the inverse-square force would imply a small but finite rest mass
for the light quantum, or photon, and consequently a slight variation
with wavelength in the speed of electromagnetic waves in vacuum. It
is known form direct observation\footnote{The best evidence so far
is a recent observation of the practically simultaneous (within a few
minutes, at most) arrival at the earth of radio emissions and light
emissions from the eruptions of a ``flare star'' 20 light-years away
from us [B.~Lovell, F.L.~Whipple, and L.H.~Solomon, \emph{Nature}
202, 377 (1964)].}  that short radio waves travel through vacuum with
the same speed as visible light, to an experimental accuracy at least
as good as one part in $10^{6}$. From this it is possible to argue
theoretically that Coulomb's law ought to be good up to distances of
several kilometers at least. Probably even stronger indirect
arguments of this sort could be made.      To summarize, we have
every reason for confidence in Coulomb's law over the enormous range
from $10^{-13}$ cm to many kilometers, if not farther, and we take it
as the foundation of our description of electromagnetism.

\section{Energy of a System of Charges}

In principle, Coulomb's law is all there is to electrostatics given
the charges and their locations we can fins all the electrical
forces. Or given that the charges are free to move under the
influence of other kinds of forces as well, we can find the
equilibrium arrangement in which the charge distribution will remain
stationary. In the same sense, Newton's laws of motion are all there
is to mechanics. But in both mechanics and electromagnetism we gain
power and insight by introducing other concepts, most notably that of
energy. Energy is a useful concept here because electric forces are
\emph{conservative}. Consider first the work which must be done
\emph{on} the system to bring some charged bodies into a particular
arrangement. Let us start as indicated at the top of Fig.~1.4,
carrying charges $q_1$ and $q_2$. Whatever energy may have been
needed to create these two concentrations of charge originally we
shall leave entirely out of account. Bring the particles slowly
together until the distance between them is $r_{12}$. How much work
does it take? It makes no difference whether we bring $q_1$ toward
$q_2$ or the other way around. In either case the work done is the
integral of the product: force times
displacement-in-direction-of-force. The force that has to be applied
to move one charge toward the other is equal and opposite to the
coulomb force.

\begin{equation}
  W = \int \text{force}\times\text{distance} 
    = \int_{r=\infty}^{r_{12}} \frac{q_1q_2(-\der r)}{r^2} = \frac{q_1q_2}{r_{12}}
\end{equation}

Because $r$ is changing from  to $r_{12}$, the increment of
displacement is $-\der r$. we know the work done on the system must be
positive for charges of like sign; they have to be pushed together.
With $q_1$ and $q_2$ in esu, and $r_{12}$ in centimeters, E. 3 gives
the work in ergs. From our study of \emph{conservative} forces in
Vol. 1 (see especially page 145, Vol.~1), we know that this work is
the same whatever the path of approach. Let's review the argument as
it applies to the two charges $q_1$ and $q_2$ in Fig.~1.5. There we
have kept $q_1$ fixed and we show $q_2$ moved to the same final
position along two different paths. Every spherical shell such as the
one indicated between $r$ and $r plus \der r$ must be crossed by both
paths. The increment of work involved, $-\vc{F}\cdot\der\vc{s}$ in this bit of path,
is the same for the two paths. The reason is that $\vc{F}$ has the same
magnitude at both places and is directed radially from $q_1$, while
$\der s = \der r/\cos\theta$; hence $\vc{F}\cdot\der\vc{s} = F\: \der r$. Each increment of work
alone one path is matched by a corresponding increment on the other,
so the sums must be equal. Our conclusion
% pp. 12-21 are not fully converted yet
holds even for paths that loop in and out, like the dotted path in
Fig. 1.5. (Why?)

Returning now to the two charges as we left them in Fig. 1.4b, let
us bring in from some remote place a third charge $q_3$ and move it to a
point $P_3$ whose distance from charge 1 is $r_{31}$ cm and from charge 2,
$r_{32}$ cm. The work required to effect this will be
\begin{equation}
  W_3 = -\int_\infty^{P_3} \vc{F}_3\cdot\der\vc{s}
\end{equation}
Thanks to the additivity of electrical interactions, which we have
already emphasized,
\begin{equation}
  -\int \vc{F}_3\cdot\der\vc{s} = - \int (\vc{F}_{31}+\vc{F}_{32})\cdot\der\vc{s}
  = -\int \vc{F}_{31}\cdot\der\vc{s} -\int \vc{F}_{32}\cdot\der\vc{s}
\end{equation}
% Purcell's use of vector dr in third expression is a mistake.
That is, the work to bring $q_3$ to $P_3$ is the sum of the work needed when
$q_1$ is present alone and that needed when $q_2$ is present alone.
\begin{equation}
  W_3 = \frac{q_1q_3}{r_{31}}+\frac{q_2q_3}{r_{32}}
\end{equation}
The total work done in assembling this arrangement of three charges,
which we shall call U, is therefore
\begin{equation}
  U = \frac{q_1q_2}{r_{21}}+\frac{q_1q_3}{r_{31}}+\frac{q_2q_3}{r_{32}}
\end{equation}
We note that $q_1$, $q_2$, and $q_3$ appear symmetrically in the expression
above, in spite of the fact that $q_3$ was brought up last. We would have
reached the same result if $q_3$ had been brought in first. (Try it.)
Thus $U$ is independent of the order in which the charges were assembled.
Since it is independent also of the route by which each charge
was brought in, $U$ must be a unique property of the final arrangement
of charges. We may call it the electrical potential energy of this par-
ticular system. There is a certain arbitrariness, as always, in the defi-
nition of a potential energy. In this case we have chosen the zero
of potential energy to correspond to the situation with the three
charges already in existence but infinitely far apart from one another.
The potential energy belongs to the configuration as a whole. There
is no meaningful way of assigning a certain fraction of it to one of the
charges.

It is obvious how this very simple result can be generalized to
apply to any number of charges. If we have $N$ different charges, in
any arrangement in space, the potential energy of the system is cal-
culated by summing over all pairs, just as in Eq. 7. The zero of
% p. 13
potential energy, as in that case, corresponds to all charges far apart.

As an example, let us calculate the potential energy of an arrange-
ment of eight negative charges on the corners of a cube of side $b$,
with a positive charge in the center of the cube, as in Fig. 1.6a. Sup-
pose each negative charge is an electron with charge $-e$, while the
central particle carries a double positive charge, $2e$. Summing over
all pairs, we have:
\begin{equation}
  U = \frac{8(-2e^2)}{(\sqrt{3}/2)b}+\frac{12e^2}{b}+\frac{12e^2}{\sqrt{2}b}
    +\frac{4e^2}{\sqrt{3}b}
    = \frac{4.32e^2}{b}
\end{equation}
Figure 1.6b shows where each term in this sum comes from. The
energy is positive, indicating that work had to be done on the system
to assemble it. That work could, of course, be recovered if we let the
charges move apart, exerting forces on some external body or bodies.
Or if the electrons were simply to ffy apart from this configuration,
the total kinetic energy of all the particles would become equal to $U$.
This would be true whether they came apart simultaneously and
symmetrically, or were released one at a time in any order. Here
we see the power of this simple notion of the total potential energy
of the system. Think what the problem would be like if we had to
compute the resultant Vector force on every particle, at every stage
of assembly of the configuration! In this example, to be sure, the
geometrical symmetry would simplify that task; even so it would be
more complicated than the simple calculation above.

One way of writing the instruction for the sum over pairs is this:
\begin{equation}
  U = \frac{1}{2} \sum_{j=1}^N \sum_{k\ne j} \frac{q_jq_k}{r_{jk}}
\end{equation}
The double-sum notation, $\sum_{j=1}^N \sum_{k\ne j}$, says: Take $j=1$ and sum over
$k = 2,\ 3,\ 4,\ldots,N$; then take $j=2$ and sum over
$k = 1,\ 3,\ 4,\ldots,N$;
and so on, through $j = N$. Clearly this includes every pair twice, and
to correct for that we put in front the factor $\frac{1}{2}$.

\section{Electrical energy in a crystal lattice}

These ideas have an important application in the physics of crys-
tals. We know that an ionic crystal like sodium chloride can be
described, to a very good approximation, as an arrangement of
positive ions ($\zu{Na}^+$) and negative ions ($\zu{Cl}^-$) alternating in a regular
three-dimensional array or lattice. In sodium chloride the arrange-
% p. 14
ment is that shown in Fig. 1.7a. Of course the ions are not point
charges, but they are nearly spherical distributions of charge and
therefore (as we shall presently prove) the electrical forces they exert
on one another are the same as if each ion were replaced by an equiv-
alent point charge at its center. We show this electrically equivalent
system in Fig. 1.7b. The electrostatic potential energy of the lattice
of charges plays an important role in the explanation of the stability
and cohesion of the ionic crystal. Let us see if we can estimate its
magnitude.

We seem to be faced at once with a sum that is enormous, if not
doubly infinite, for any macroscopic crystal contains $10^{20}$ atoms at
least. Will the sum converge? Now what we hope to find is the
potential energy per unit volume or mass of crystal. We confidently
expect this to be independent of the size of the crystal, on the general
argument that one end of a macroscopic crystal can have little in-
ffuence on the other. Two grams of sodium chloride ought to have
twice the potential energy of one gram, and the shape should not be
important so long as the surface atoms are a small fraction of the total
number of atoms. We would be wrong in this expectation if the crys-
tal were made out of ions of one sign only. Then, one gram of crystal
would carry an enormous electric charge and putting two such crys-
tals together to make a two-gram crystal would take a fantastic
amount of energy. (You might estimate how much!) The situation
is saved by the fact that the crystal structure is an alternation of equal
and opposite charges, so that any macroscopic bit of crystal is very
nearly neutral.

To evaluate the potential energy we first observe that every posi-
tive ion is in a position equivalent to that of every other positive ion.
Furthermore, although it is not perhaps immediately obvious from
Fig. 1.7, the arrangement of positive ions around a negative ion is
exactly the same as the arrangement of negative ions around a posi-
tive ion, and so on. Hence we may take one ion as a center, it matters
not which kind, sum over its interactions with all the others, and
simply multiply by the total number of ions of both kinds. This
reduces the double sum in Eq. 9, to a single sum and a factor N; we
must still apply the factor $\frac{1}{2}$ to compensate for including each pair
twice. That is, the energy of a sodium chloride lattice composed of
a total of $N$ ions is
\begin{equation}
  U = \frac{1}{2} N \sum_{k=2}^N \frac{q_1q_k}{r_{1k}}
\end{equation}
% p. 15
Taking the positive ion at the center as in Fig. 1.7b, our sum runs
over all its neighbors near and far. The leading terms start out as
follows:
\begin{equation}
  U = \frac{1}{2} N \left[-\frac{6e^2}{a}+\frac{12e^2}{\sqrt{2}a}-\frac{8e^2}{\sqrt{3}a}+\ldots\right]
\end{equation}
The first term comes from the six nearest chlorine ions, at distance
a, the second from the twelve sodium ions on the cube edges, and so
on. It is clear, incidentally, that this series does not converge abso-
lutely; if we were so foolish as to try to sum all the positive terms
first, that sum would diverge. To evaluate such a sum, we should
arrange it so that as we proceed outward, including ever more distant
ions, we include them in groups which represent nearly neutral shells
of material. Then if the sum is broken oil", the more remote ions
which have been neglected will be such an even mixture of positive
and negative charges that we can be confident their contribution
would have been small. This is a crude way to describe what is
actually a somewhat more delicate computational problem. The
numerical evaluation of such a series is performed nowadays with an
electronic computer. The answer in this example happens to be:
\begin{equation}
  U = \frac{-0.8738Ne^2}{a}
\end{equation}
Here $N$, the number of ions, is twice the number of NaCl molecules.

The negative sign reffects the dominance of the nearest neighbors,
and shows that work would have to be done to take the crystal apart
into ions. In other words, the electric energy helps to explain the
cohesion of the crystal. If this were the whole story, however, the
crystal would collapse, for the potential energy of the charge dis-
tribution is obviously louiered by an overall reduction in the spac-
ing a. We meet here again the familiar dilemma of classica1--that
is, nonquantum--physics. No system can be in stable equilibrium,
according to classical laws, under the action of electric forces alone.
Does this make our analysis useless? Not at all. Remarkably, and
happily, in the quantum physics of crystals the electric potential
energy can still be given meaning, and can be computed very much
in the way we have learned here.

% p. 16
\section{The electric field}

Suppose we have some arrangement of charges, $q_1$, $q_2$, \ldots , $q_N$,
fixed in space, and we are interested not in the forces they exert on
one another but only in their effect on some other charge qo which
might be brought into their vicinity. We know how to calculate the
resultant force on this charge, given its position which we may specify
by the coordinates $x$, $y$, $z$. The force on the charge $q_0$ is:
\begin{equation}
  \vc{F} = \sum_{j=1}^N \frac{q_0q_j\hat{\vc{r}}_{0j}}{r_{0j}^2}
\end{equation}
where $\vc{r}_{0j}$ is the vector from the $j$th charge in the system to the point
$(x,y,z)$. The force is proportional to $q_0$, so if we divide out $q_0$ we
obtain a vector quantity which depends only on the structure of our
original system of charges, $q_1$, \ldots , $q_N$ and on the position of the point
(x,y,z). We call this vector function of $x$, $y$, $z$ the electric field arising
from the $q_1$, \ldots , $q_N$, and use the symbol $\vc{E}$ for it. The charges
$q_1$, \ldots , $q_N$ we call sources of the field. We may take as the definition
of the electric field $\vc{E}$ of a charge distribution, at the point $(x,y,z)$
\begin{equation}
  \vc{E}(x,y,z) = \sum_{j=1}^N \frac{q_j\hat{\vc{r}}_{0j}}{r_{0j}^2}
\end{equation}
Fig. 1.8 illustrates the vector addition of the field of a point charge
of $+2$ esu to the field of a point charge of $-1$ esu, at a particular
point in space. In the CGS system of units, electric field strength is
expressed in dynes per unit charge, that is, dynes/esu.

So far we have nothing really new. The electric field is merely
another way of describing the system of charges; it does so by giving
the force per unit charge, in magnitude and direction, that an ex-
ploring charge $q_0$ would experience at any point. We have to be a
little careful with that interpretation. Unless the source charges are
really immovable, the introduction of some finite charge $q_0$ may
cause the source charges to shift their positions, so that the field itself,
as defined by Eq. 14, is difierent. That is why we assumed fixed
charges to begin our discussion. People sometimes define the field
by requiring $q_0$ to be an "infinitesimal" test charge, letting E be the
limit of $F/q_0$ as $q_0\rightarrow0$. Any flavor of rigor this may impart is illu-
sory. Remember that in the real world we have never observed a
charge smaller than $e$! Actually, if we take Eq. 14 as our definition
of E, without reference to a test charge, no problem arises and the
sources need not be fixed. If the introduction of a new charge
% p. 17
causes a shift in the source charges, then it has indeed brought about
a change in the electric field, and if we want to predict the force on
the new charge, we must use the new electric field in computing it.

Perhaps you still want to ask, what is an electric field? Is it some-
thing real, or is it merely a name for a factor in an equation which has
to be multiplied by something else to give the numerical value of the
force we measure in an experiment? Two observations may be use-
ful here. First, since it works, it doesn't make any difference. That
is not a frivolous answer, but a serious one. Second, the fact that
the electric field vector at a point in space is all we need know to
predict the force that will act on any charge at that point is by no
means trivial. It might have been otherwise! If no experiments
had ever been done, we could imagine that in two different situa-
tions in which unit charges experience equal force, test charges of
strength 2 units might experience different forces, depending on the
nature of the other charges in the system. If that were true, the field
description wouldn't work.

The electric field attaches to every point in a system a local prop-
erty, in this sense: If we know \vc{E} in some small neighborhood, we
know, without further inquiry, what will happen to any charges in
that neighborhood. We don't need to know what produced the field.
If we know the electric field at all points in space, we have a com-
plete description of the whole system, one that will reveal the posi-
tions and magnitudes of all the charges.

To visualize an electric field, you need to associate a vector, that is,
a magnitude and direction, with every point in space. We shall use
various schemes, none of them wholly satisfactory, to depict vector
fields in this book.

It is hard to draw in two dimensions a picture of a vector function
in three-dimensional space. We can indicate the magnitude and
direction of $\vc{E}$ at various points by drawing little arrows near those
points, making the arrows longer where $E$ is larger.\footnote{Such
a representation is rather clumsy at best. It is hard to indicate the point in
space to which a particular vector Value applies, and the range of magnitudes of E is
usually so large that it is impracticable to make the lengths of the arrows proportional
to E.
} Using this
scheme, we show in Fig. 1.9a the field of an isolated point charge of
$+3$ units and in Fig. 1.9b the field of a point charge of $-1$ unit.
These pictures admittedly add nothing whatever to our understand-
ing of the field of an isolated charge; anyone can imagine a simple
radial inverse-square field without the help of a picture. We show
% p. 18
them in order to combine the two fields in Fig. 1.10, which indicates
in the same manner the field of two such charges separated by a
distance $a$. All that Fig. 1.10 can show is the field in a plane con-
taining the charges. To get a full three-dimensional representation
one must imagine the figure rotated around the symmetry axis. In
Fig. 1.10 there is one point in space where $\vc{E}$ is zero. How far from
the nearer charge must this lie? Notice also that toward the edge of
the picture the field points more or less radically outward all around.
One can see that at a very large distance from the charges the field
will look very much like the field from a positive point charge. This
is to be expected because the separation of the charges cannot make
very much difference for points far away, and a point charge of $+2$
units is just what we would have left if we superimposed our two
sources at one spot.

Another way to depict a Vector field is to draw field lines. These
are simply curves whose tangent, at any point, lies in the direction of
the field at that point. Such curves will be smooth and continuous
except at singularities such as point charges, or points like the one
in the example of Fig. 1.10 where the field is zero. A field line plot

% p. 19
does not directly give the magnitude of the field, although we shall
see that, in a general way, the field lines converge as we approach a
region of strong field and spread apart as we approach a region of
weak field. In Fig. 1.11 are drawn some field lines for the same ar-
rangement of charges as in Fig. 1.10, a positive charge of 3 units and
a negative charge of one unit. Again, we are restricted by the nature

of paper and ink to a two-dimensional section through a three-
dimensional bundle of curves.

% p. 20
\section{Charge distributions}

This is as good a place as any to generalize from point charges to
continuous charge distributions. A volume distribution of charge is
described by a scalar charge-density function $\rho$, which is a function
of position, with the dimensions charge/volume. That is, $\rho$ times a
volume element gives the amount of charge contained in that volume
element. The same symbol is often used for mass per unit volume,
but in this book we shall always give charge per unit volume first
% p. 21
call on the symbol $\rho$. If we write $\rho$ as a function of the coordinates
$x$, $y$, $z$, then $\rho(x,y,z)\der x \der y \der z$ is the charge contained in the little box,
of volume $\der x \der y \der z$, located at the point $(x,y,z)$.

On an atomic scale, of course, the charge density varies enor-
mously from point to point; even so it proves to be a useful concept
in that domain. However we shall use it mainly when we are dealing
with large-scale systems, so large that a volume element do =
dx dy dz can be quite small relative to the size of our system although
still large enough to contain many atoms or elementary charges.
As we have remarked before, we face a similar problem in defining
the ordinary mass-density of a substance.

If the source of the electric field is to be a continuous charge dis-
tribution rather than point charges, we have only to replace the sum
in Eq. 13 with the appropriate integral. The integral gives the elec-
tric field at $(x,y,z)$, which is produced by charges at other points
$(x',y',z')$.
\begin{equation}
  \vc{E}(x,y,z) = \int \frac{\rho(x',y',z')\hat{\vc{r}}\der x' \der y' \der z'}{r^2}
\end{equation}
This is a volume integral. Holding $(x,y,z)$ fixed we let the variables
of integration $x'$, $y'$, and $z'$ range over all space containing charge,
thus summing up the contributions of all the bits of charge. The
unit vector $\hat{\vc{r}}$ points from $(x', y', z')$ to $(x,y,z)$ --- 
unless we want to put
a minus sign before the integral in which case we may reverse the
direction of $\hat{\vc{r}}$. It is always hard to keep signs straight. Let's re-
member that the electric field points away from a positive source
(Fig. 1.12).

In the neighborhood of a true point charge the electric field grows
infinite like $1/r^2$ as we approach the point. It makes no sense to talk
about the field at the point charge. As our ultimate physical sources
of field are not, we believe, infinite concentrations of charge in zero
volume but instead finite structures, we simply ignore the mathe-
matical singularities implied by our point-charge language and rule
out of bounds the interior of our elementary sources. It may be
worth noting, nevertheless, that a continuous charge distribution
contains no threat of a singularity, and allows the field to be defined
at points inside the distribution itself. That is because the volume
integral in Eq. 15 is prevented from blowing up in the neighborhood
of $r = O$ by the fact that the volume element itself goes as $r^2 \der r$. That
is to say, so long as $\rho$ remains finite, the field will remain finite every-
where, even in the interior or on the boundary of a charge
distribution.


\section{Flux}\index{flux}

The relation between the electric field and its sources can be
expressed in a remarkable simple way, one that we shall find very
useful. For this we need to define a quantity called \emph{flux}.

Consider some electric field in space and in this space some
arbitrary closed surface, like a balloon of any shape. Figure 1.13
shows such a surface, the field being suggested by a few field lines.
Now divide the whole surface into little patches which are so small
that over any on patch the surface is practically flat and the vector
field does not change appreciably from one part of a patch to
another. In other words, don't let the balloon be too crinkly, and
don't let its surface pass right through a singularity\footnote{By a
singularity of the field we would ordinarily mean not only a point
source where the field approaches infinity, but any place where the
field changes magnitude or direction discontinuously, such as an
infinitesimally thin layer of concentrated charge.
Actually this latter, milder, kind of singularity would cause no
difficulty here unless out balloon's surface were to coincide with
the surface of discontinuity over some finite area.} of the field
such as a point charge. The area of a patch defines a unique
direction ---the outward-pointing normal to its surface. (Since the
surface is closed you can tell its inside from its outside; there is
no ambiguity.) Let this magnitude and direction be represented by a
vector. Then for every patch into which the surface has been divided,
such as patch number $j$, we have a vector $\vc{a}_j$, giving its area
and orientation. The steps we have just taken are pictured in Fig.
1.13b and c. Note the vector $\vc{a}_j$ does not depend at all on
the shape of the patch; it doesn't matter how we have divided up the
surface, as long as the patches are small enough.

Let $\vc{E}_j$ be the electric field vector at the location of patch
number $j$. The scalar product $\vc{E}_j \cdot a_j$ is a number.
We call this number the \emph{flux} through that bit of surface.
To understand the origin of the same name, imagine a vector function
which represents the velocity of motion in a fluid ---say in a river,
where the velocity varies from one place to another but is constant
in time at any one position. Denote this vector field by $v$,
measured, say, in feet per second. Then if $a$ is the oriented area,
in square feed, of a frame lowered into the water, $\vc{v} \cdot \vc{a}$
is the \emph{rate of flow} of water through the fame in cubic feet
per second (Fig.~1.14). We must emphasize that our definition of
flux is applicable to any vector function, whatever physical variable
it may represent.

Now let us add up all the flux through all the patches to get the
flux through the entire surface, a scalar quantity which we shall
denote by $\Phi$:
\begin{equation} 
  \Phi= \sum\limits_{\text{All}~j}\vc{E}_j \cdot \vc{a}_j 
\end{equation}
Letting the paths become smaller and more numerous without limit, we
pass from the sum in Eq. 16 to a surface integral:
\begin{equation}
  \Phi= \int\nolimits_{\substack{\text{Entire}\\\text{surface}}}\vc{E} \cdot d\vc{a}
\end{equation}
A surface integral of any vector function $\vc{F}$, over a surface
$S$, means just this: Divide $S$ into small patches, each represented
by a vector outward, of magnitude equal to the patch area; at every
patch, take the scalar product of the patch area vector and the local
$\vc{F}$; sum all these products, and the limit of this sum, as the
patches shrink, is the surface integral, Do not be alarmed by the
prospect of having to perform such a calculation for an awkwardly
shaped surface like the one in Fig.~1.13. The surprising property
we are about to demonstrate makes that unnecessary!

\section{Gauss's law}\index{Gauss's law}

Take the simplest case imaginable; suppose the field is that of a
single isolated positive point charge $q$ and the surface is a sphere
of radius $r$ centered on the point charge (Fig.~1.15. What is the
flux $\Phi$ through this surface? The answer is easy because the
magnitude of $\vc{E}$ at every point on the surface is $q/r^2$ and its
direction is the same as that of the outward normal at that point.
So we have:
\begin{equation} 
  \Phi =  {\vc{E}}\times \text{total area} = \frac{q}{r^2} \times 4\pi r^2 =  4\pi q 
\end{equation}
The flux is independent of the size of the sphere.

% p. 24

Now imagine a second surface, or balloon, enclosing the first, but
\emph{not} spherical, as in Fig 1.16. We claim that the total flux
through this surface is the same as that through the sphere.
To see this, look at a cone, radiating from $q$, which cuts a small
patch $\vc{a}$ out of the sphere and continues on to the outer surface
where it cuts out a patch $\vc{A}$ at a distance $R$ from the point
charge. The area of the patch $\vc{A}$ is larger than that of the patch
$\vc{a}$ by two factors: first, by the ration of the distance squared
$(R/r)^2$; and second, owing to its inclination, by the factor
$(1/\cos\theta)$. The angle $\theta$ is the angle between the outward
normal and the radial direction (see Fig.~1.16). The electric field
in that neighborhood is reduced from its magnitude on the sphere by
the factor $(r/R)^2$ and is still radially directed.
Letting $\vc{E}_{(r)}$ be the field at the sphere,
we have:

\begin{gather*}
\text{Flux through outer patch} =  \vc{E}_{(R)} \cdot \vc{A} =   E_ {(R)}  A\cos\theta \\
\text{Flux through inner patch} =  \vc{E}_ {(r)} \cdot \vc{a} =   E_ {(r)}  a \\
E_r A\cos\theta =  \left[E_r \left(\frac{r}{(R)} \right)^2  \right]
                   \left[a\left(\frac{R}{r} \right)^2  \frac{1}{\cos\theta}\right]
                   \cos\theta =  E_r a
\end{gather*}

\noindent This proves the flux through the two patches is the same.

Now every patch on the outer surface can in this way be put into
correspondence with part of the spherical surface, so the total flux
must be the same through the two surfaces. That is, the flux through
the new surface must be just $4 \pi q$. But this was a surface of
\emph{arbitrary} shape and size.\footnote{To be sure, we had the
second surface enclosing the sphere, but it didn't have to, really.
Besides, the sphere can betaken as small as we please.} We conclude:
the flux of the electric field through \emph{any} surface enclosing a
point charge $q$ is $4 \pi q$. As a corollary we can say that the
goal flux through a closed surface is \emph{outside} the surface. We
leave the proof of this to the reader, along with Fig.~1.17 as a
hint of one possible line of argument.

There is a way of looking at all this which makes the result seem
obvious. Imagine at $q$ a source which emits particles ---such as
bullets or photons ---in all directions at a steady rate. Clearly the
flux of particles through a window of unit area will fall off with
the inverse square of the window's distance from $q$. Hence we can
draw an analogy between the electric field strength $E$ and the
intensity of particle flow in bullets per unit area per unit time. It
is pretty obvious that the flux of bullets through any surface
completely surrounding $q$ is independent of the size and shape of
that surface, for it is just the total number emitted per unit time.
Correspondingly, the flux of $E$ through the closed surface must be
independent of size 
% p. 25
and shape. The common feature
responsible for this is the inverse-square behavior of the intensity.

The situation is now ripe for superposition! Any electric field is
the sum of the fields of its individual sources. This property was
expressed in our statement, Eq. 13, of Coulomb's law. Clearly flux
is an additive quantity in the same sense, for if we have a number of
sources $q_1$, $q_2$, \ldots $q_N$, the fields of which, if each were
present alone, would be $\vc{E}_1$, $\vc{E}_2$, \ldots $\vc{E}_N$, the
flux $\Phi$ through some surface $S$ in the actual field can be written

\begin{equation}
  \Phi =  \int\nolimits_{S}{} E \cdot d
  \vc{a} =  \int\nolimits_{{S}}{}[\vc{E}_1 +
  \vc{E}_2 + \ldots + \vc{E}_N] \cdot d \vc{a} 
\end{equation}

We have just learned that $\int\nolimits_{S}{} \vc{E} \cdot d\vc{a}$
equals $4 \pi q_n$ if the charge $q_n$ is inside $S$ and
equals zero otherwise. So every charge $q$ inside the surface
contributes exactly $4 \pi q$ to the surface integral of Eq. 20 and
all charges outside contribute nothing. We have arrived at Gauss's
law:

\begin{framed}
The flux of the electric field \vc{E} through any closed surface,
that is, the integral $\int {\vc{E}} \cdot d \vc{a}$ over
the surface, equals $4\pi$ times the goal charge enclosed by the
surface:

\begin{equation} 
  \int {\vc{E}} \cdot d \vc{a} =  4\pi \sum_i q_i =  4\pi \int \rho dv 
\end{equation}
\end{framed}

We call the statement in the box a \emph{law} because it is
equivalent to Coulomb's law and could serve equally well as the basic
law of electrostatic interactions, after charge and field have been
defined. Gauss's law and Coulomb's law are not two independent
physical laws, but the same law expressed in different ways.
\footnote{There is one difference, inconsequential here, but relevant
to our later study of the fields of moving charges. Gauss's law is
obeyed by a wider class of fields than those represented by the
electrostatic fired. In particular, a field that is inverse-square in
$r$ but not spherically symmetrical can satisfy Gauss's law.

In other words, Gauss's law alone does not imply the symmetry of the
field of a point source which is implicit in Coulomb's law.}

Looking back over our proof, we see that it hinged on the
inverse-square nature of the interaction and of course on additivity
of interactions, or superposition. Thus the theorem is applicable to
any inverse-square field in physics, for instance to the
gravitational field, as discussed in Vol. I, Chap. $9$.

It is easy to see that Gauss's law would \emph{not} hold if the law
of force were, say, inverse-cube. For in that case the flux of
electric field 
% p. 26
from a point charge $q$ through a sphere
through a sphere of radius $R$ centered on the charge would be

\begin{equation} 
\Phi =  \vc{\int E} \cdot d \vc{a} = \frac{q}{R^3} \cdot 4 \pi R^2 =  \frac{4 \pi q}{R}
\end{equation}

By making the sphere large enough we could make the flux through it
as small as we pleased, while the total charge inside remained
constant.

This remarkable theorem enlarges our graph in two ways. First, it
reveals a connection between the field and its sources that is
converse to Coulomb's law. Coulomb's law tells us how to derive the
electric field if the charges are given; with Gauss's law we can
determine how much charge is in any region if the field is known.

Second, the mathematical relation here demonstrated is a powerful
analytic tool; it can make complicated problems easy, as we shall see.

\section{Field of a spherical charge distribution}

We can use Gauss's law to find the electric field of a spherically
symmetrical distribution of charge, that is, a distribution in which
the charge density $\rho$ depends only on the radius from a central
point. Figure 1.18 depicts a cross section through some such
distribution. In this one the charge density is high at the center,
decreases and then rises again with increasing distance from the
center, and is ero beyond $r_0$. What is the electric field at some
point such as $P_1$ arising from each elementary volume in the charge
distribution. Lets try a different approach which exploits both the
symmetry of the system and Gauss's law.

Because of the spherical symmetry, the electric field at any point
must be radially directed ---no other direction is unique.

Likewise, the field magnitude $E$ must be the same at all points on a
spherical surface $S_1$ of radius $r_1$, for all such points are
equivalent. Call this field magnitude $E_1$. The flux through this
surface $S_1$ is therefore simply $4 \pi r_1^2E_1$, and by Gauss's
law this must be equal to $4\pi$ times the charge enclosed by the
surface. That is, $4 \pi r_1^2E_1 =  4\pi$ (charge inside $S_1$ or

\begin{equation} 
  E_1 =  \frac{\text{charge inside $S_1$}}{r_1^2}
\end{equation}
